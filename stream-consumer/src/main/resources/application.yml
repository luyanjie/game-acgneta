server:
  port: 7889
spring:
  application:
    name: dynamic-stream
  datasource:
    game2element:
      url: jdbc:mysql://192.168.40.6:3306/Game2Element?useUnicode=true&characterEncoding=utf-8&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC&allowMultiQueries=true
      username: servergroup
      password: tongbuserver
      driverClassName: com.mysql.cj.jdbc.Driver
  mvc:
    throw-exception-if-no-handler-found: true  # 出现错误时, 直接抛出异常
  resources:
    add-mappings: false #不要为我们工程中的资源文件建立映射
  cloud:
    stream:
      kafka:
        binder:
          brokers: 192.168.40.155:9092 #Kafka的消息中间件服务器,多个用逗号隔开
          #zk-nodes: 192.168.40.155:2181 # #Zookeeper的节点，如果集群，后面加,号分隔 spring cloud 2.0版本以后就不需要了
          auto-create-topics: true # 如果设置为false,就不会自动创建Topic 有可能你Topic还没创建就直接调用了。
          auto-add-partitions: true
          min-partition-count: 1
      bindings:
        dynamicInput: # 自定义myInput 接收
          destination: dynamic
          content-type: text/plain #application/json
          group: acgneta #分组的组名 同个分组的消费者的一条消息只能被一个消费者接受，也就是不会被重复消费,该端口号生成多个consumer
          consumer:
            # 为true(default)时，多个实例会自动均衡 不需要这些属性：instanceCount，instanceIndex，partitioned
            # 为false时，binder使用instanceCount and instanceIndex决定实例订阅哪个partition
            # partition数量至少要与实例数量一致
            # binder代替Kafka计算partitions
            # 这可以让特定分区的消息始终进入同一个实例
            autoRebalanceEnabled: true
            #autoCommitOffset: true
            concurrency: 1
            partitioned: true # 开启分区
        output: # 进行消息中转处理后，在进行转发出去（去项目spring-cloud-stream-consumer2接收）
          destination: zhhtest
